{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy.special\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = [8, 6]\n",
    "matplotlib.rcParams['font.size'] = 16 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analytic Exercise #2 (numerical addendum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The noise in a data set is determined by the Poisson noise in\n",
    "the expectation value of the signal. However, observationally we often\n",
    "only have access to one realization of the signal, and often the\n",
    "quoted errors are based on the Poisson noise in that signal.  If we\n",
    "take multiple observations and combine them together weighting by the\n",
    "inverse variance estimated in this way, it leads to a bias. Ignoring\n",
    "any background contribution to the noise, estimate this bias as a\n",
    "function of $n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analytic_biased_mean(nbar, N):\n",
    "    bm = (nbar / (1. + 1. / nbar) * \n",
    "          (1. + (1. / N) * (1. / nbar) * (1. - 1 / nbar) / (1. + 1. / nbar)**2))\n",
    "    return(bm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_biased_mean(nbar, N, ntrial=100000):\n",
    "    ntrial = 100000\n",
    "    nest = np.zeros(ntrial, dtype=np.float32)\n",
    "    for j in np.arange(ntrial, dtype=np.int32):\n",
    "        ni = np.float32(np.random.poisson(lam=nbar, size=N))\n",
    "        ni[ni == 0.] = 1.\n",
    "        nest[j] = np.float32(N) / (1. / ni).sum()\n",
    "    return(nest.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n"
     ]
    }
   ],
   "source": [
    "N = 10\n",
    "nnbars = 100\n",
    "nbars = 0.5 + (100. - 0.5) * np.arange(nnbars, dtype=np.float32) / np.float32(nnbars - 1)\n",
    "analytics = np.zeros(nnbars, dtype=np.float32)\n",
    "mcs = np.zeros(nnbars, dtype=np.float32)\n",
    "for i in np.arange(nnbars, dtype=np.int32):\n",
    "    print(i)\n",
    "    nbar = nbars[i]\n",
    "    analytics[i] = analytic_biased_mean(nbar, N)\n",
    "    mcs[i] = mc_biased_mean(nbar, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(nbars, mcs / nbars, color='black', label='MCs')\n",
    "plt.plot(nbars, analytics / nbars, color='red', label='Analytic approx.')\n",
    "plt.plot(nbars, np.ones(nnbars, dtype=np.float32), color='black', linestyle='dotted')\n",
    "plt.xlabel(r'$\\bar n$')\n",
    "plt.ylabel(r'$\\langle \\hat n \\rangle / \\bar n$')\n",
    "plt.ylim([0.95, 1.05])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When $\\bar n$ is low, using $n$ as an estimate of its own variance gets very lousy, and the estimate of $n$ from multiple observations averaged by the inverse variance is very overestimated. This can be changed depending on how $n=0$ observations are treated.\n",
    "\n",
    "At higher $\\bar n$ the estimate gets better but generally will lead to an underestimate. The approximate model for this bias is not bad above $\\bar n \\sim 10$ or so (depending on the precision you need!). Note that this implies that even for $\\bar n \\approx 100$, using the data itself for an inverse variance estimate leads to a 1\\% bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
